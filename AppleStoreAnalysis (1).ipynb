{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the types of apps that attract the most users in Google Play and App Store?\n",
    "\n",
    "*To do this, we need to collect and analyse data about mobile apps available on Google Play and the App Store.*\n",
    "\n",
    "*As of September 2018, there were approximately 2 million iOS apps available on the App Store, and 2.1 million Android apps on Google Play.*\n",
    "\n",
    "*We have two data sets:*\n",
    "    *1. A data set containing data about approximately __7,000 IOS apps__ from the __App Store__, the data was collected in __July 2017__;* \n",
    "    *2. A data set containing data about approximately __10,000 Android apps__ from __Google Play__, the data was collected in __August 2018__.*\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)   #printeaza fiecare row dintr-un anumit slice\n",
    "        print('\\n')\n",
    "        \n",
    "    if rows_and_columns:   # if True, afiseaza nr de coloane si randuri\n",
    "        print('Number of rows: ', len(dataset))\n",
    "        print('Number of columns: ', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file_Apple = open('AppleStore.csv', encoding=\"utf8\")\n",
    "open_file_Google = open('GooglePlayStore.csv',encoding=\"utf8\")\n",
    "\n",
    "from csv import reader\n",
    "read_file_Apple = reader(open_file_Apple)\n",
    "read_file_Google = reader(open_file_Google)\n",
    "\n",
    "Apple_data = list(read_file_Apple)\n",
    "Google_data = list(read_file_Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The header in the App Store dataset:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "ios_header = Apple_data[0]\n",
    "print(ios_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the Apple Store dataset: 7198\n",
      "The number of columns in the Apple Store dataset: 16\n"
     ]
    }
   ],
   "source": [
    "print('The number of rows in the Apple Store dataset:', len(Apple_data))\n",
    "print('The number of columns in the Apple Store dataset:', len(Apple_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The header in the Google Store dataset:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n"
     ]
    }
   ],
   "source": [
    "android_header = Google_data[0]\n",
    "print(android_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the Google Store dataset 10842\n",
      "The number of columns in the Google Store dataset 13\n"
     ]
    }
   ],
   "source": [
    "print('The number of rows in the Google Store dataset', len(Google_data))\n",
    "print('The number of columns in the Google Store dataset', len(Google_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems so far that we have 7198 IOS apps in the Apple Store, and 10842 Android apps in the Google Store. \n",
    "\n",
    "Now, since we are interested only in the apps that are __free__ and directed toward an __English speaking audience__, we will have to make sure that our our datasets reflect that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "_Removing or correcting wrong data, removing duplicate data and modifying data to fit the purpose of our analysis._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the users has noticed an error to one of the rows in the data, that we need to explore. Link, [here](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015). \n",
    "It seems that the issue is in the Google Store dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(Google_data[10473])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android_header)\n",
    "print(Google_data[10473])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TownWiFi | Wi-Fi Everywhere', 'COMMUNICATION', '3.9', '2372', '58M', '500,000+', 'Free', '0', 'Everyone', 'Communication', 'August 2, 2018', '4.2.1', '4.2 and up']\n",
      "\n",
      "\n",
      "['Jazz Wi-Fi', 'COMMUNICATION', '3.4', '49', '4.0M', '10,000+', 'Free', '0', 'Everyone', 'Communication', 'February 10, 2017', '0.1', '2.3 and up']\n",
      "\n",
      "\n",
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "\n",
      "\n",
      "['osmino Wi-Fi: free WiFi', 'TOOLS', '4.2', '134203', '4.1M', '10,000,000+', 'Free', '0', 'Everyone', 'Tools', 'August 7, 2018', '6.06.14', '4.4 and up']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(Google_data,10470, 10475, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having checked the data row flagged by the user against the android header and other data slices, we have noticed that the dataset at the 10473th row is indeed not correct as it doesn't have category attached. \n",
    "\n",
    "We will delete that row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10842\n",
      "10841\n"
     ]
    }
   ],
   "source": [
    "print(len(Google_data))\n",
    "#del(Google_data[10473]) # This has been run, the wrong data point has been deleted, proof below \n",
    "print(len(Google_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Now let's inspect whether there are any duplicates in our datasets.\n",
    "We will create a dictionary that maintains all the unique values that we will be comparing against.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Apple Store \n",
    "## Identify Duplicates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7198\n",
      "284882215\n",
      "Facebook\n"
     ]
    }
   ],
   "source": [
    "print(len(Apple_data))\n",
    "print(Apple_data[1][0])\n",
    "print(Apple_data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#print(len(Apple_data)-1) # -1 because we don't count the header in\n",
    "\n",
    "def frequency_var(dataset, column): #create a function to identify duplicates\n",
    "\n",
    "    frequency_table = {} \n",
    "\n",
    "    for row in dataset[1:]:\n",
    "        var = row[column]    \n",
    "        if var in frequency_table:\n",
    "            frequency_table[var] += 1\n",
    "        else:\n",
    "            frequency_table[var] = 1\n",
    "    \n",
    "    duplicate_list = []\n",
    "    \n",
    "    if len(frequency_table) != (len(dataset)-1): #daca intr-adevar exista duplicate, trecem sa cautam care sunt acestea\n",
    "        for i in frequency_table:\n",
    "            if frequency_table[i] != 1:\n",
    "                duplicate_list.append(i) #creates a list with the duplicates\n",
    "    return duplicate_list\n",
    "\n",
    "apple_id = frequency_var(Apple_data,0)\n",
    "print(apple_id)\n",
    "\n",
    "apple_track = frequency_var(Apple_data,1)\n",
    "print(apple_track) #There are two duplicates - to Investigate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "print(ios_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We have identified two duplicates for track_name 'Mannequin Challenge' and 'VR Roller Coaster'. Now, let's identify how many data entries there are and at what index in the dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic'] \n",
      "\n",
      "Row at index: 2949 \n",
      " ['1173990889', 'Mannequin Challenge', '109705216', 'USD', '0.0', '668', '87', '3.0', '3.0', '1.4', '9+', 'Games', '37', '4', '1', '1']\n",
      "Row at index: 4443 \n",
      " ['952877179', 'VR Roller Coaster', '169523200', 'USD', '0.0', '107', '102', '3.5', '3.5', '2.0.0', '4+', 'Games', '37', '5', '1', '1']\n",
      "Row at index: 4464 \n",
      " ['1178454060', 'Mannequin Challenge', '59572224', 'USD', '0.0', '105', '58', '4.0', '4.5', '1.0.1', '4+', 'Games', '38', '5', '1', '1']\n",
      "Row at index: 4832 \n",
      " ['1089824278', 'VR Roller Coaster', '240964608', 'USD', '0.0', '67', '44', '3.5', '4.0', '0.81', '4+', 'Games', '38', '0', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "\n",
    "print(ios_header,'\\n')\n",
    "\n",
    "for i in Apple_data[1:]:\n",
    "    if i[1] == 'Mannequin Challenge':\n",
    "        print('Row at index:', index,'\\n', i)\n",
    "    elif i[1] == 'VR Roller Coaster':\n",
    "        print('Row at index:', index, '\\n', i)\n",
    "       \n",
    "    index += 1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Having looked at the data, it seems that the data have been captured at two different times, as per below:\n",
    "     __'Mannequin Challenge'__ once at __rating_count_tot__ (no of ratings) of __107__ and once at __668__\n",
    "     __'VR Roller Coaster'__ once at __rating_count_tot__ (no of ratings) of __67__ and once at __105__*\n",
    "     \n",
    "We will keep the data entries with the highest number of ratings, as it is a more recent and thus, accurate data entry. \n",
    "\n",
    "Rows __4832__ and __4464__ will be deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1062002361', 'LumaFX - infinite video effects', '13921280', 'USD', '2.99', '67', '11', '4.0', '4.5', '2.0.3', '4+', 'Photo & Video', '37', '5', '8', '1']\n",
      "['1041406978', 'DOFUS Touch', '3366912', 'USD', '0.0', '104', '3', '4.0', '4.0', '1.9.28', '12+', 'Games', '37', '5', '6', '1']\n"
     ]
    }
   ],
   "source": [
    "#del(Apple_data[4832])  #has been actioned\n",
    "#del(Apple_data[4464])  #has been actioned\n",
    "\n",
    "print(Apple_data[4832]) #successful deletion \n",
    "print(Apple_data[4464]) #successful deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Store\n",
    "## Identify Duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote the function __'frequency_var'__ earlier, that will be used on this occassion as well.\n",
    "\n",
    "As a reminder, see the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The are:  10840  Google apps \n",
      "\n",
      "Number of duplicate apps: 1181\n",
      "\n",
      "\n",
      "Examples of duplicate apps: ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses', 'HipChat - Chat Built for Teams', 'Xero Accounting Software']\n"
     ]
    }
   ],
   "source": [
    "print('The are: ', len(Google_data)-1,' Google apps','\\n') # -1 because we don't count the header in\n",
    "\n",
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "for app in Google_data[1:]:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)\n",
    "    \n",
    "print('Number of duplicate apps:', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Examples of duplicate apps:', duplicate_apps[:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain cases, we want to keep only one data entry per app. We could delete the extra entries at random but there must be a better way for sure. \n",
    "\n",
    "Let's see what differs within the data sets with the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Box', 'BUSINESS', '4.2', '159872', 'Varies with device', '10,000,000+', 'Free', '0', 'Everyone', 'Business', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Box', 'BUSINESS', '4.2', '159872', 'Varies with device', '10,000,000+', 'Free', '0', 'Everyone', 'Business', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Zenefits', 'BUSINESS', '4.2', '296', '14M', '50,000+', 'Free', '0', 'Everyone', 'Business', 'June 15, 2018', '3.2.1', '4.1 and up']\n",
      "['Box', 'BUSINESS', '4.2', '159872', 'Varies with device', '10,000,000+', 'Free', '0', 'Everyone', 'Business', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Zenefits', 'BUSINESS', '4.2', '296', '14M', '50,000+', 'Free', '0', 'Everyone', 'Business', 'June 15, 2018', '3.2.1', '4.1 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android_header)\n",
    "print('\\n')\n",
    "\n",
    "for x in Google_data[1:]:\n",
    "    name = x[0]\n",
    "    if name == 'Box':\n",
    "        print(x)\n",
    "    elif name == 'Zenefits':\n",
    "        print(x)\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above seem identical, let's look draw some more data points. It may be the case that the date differs or there are more installs, which indicates that we would be more inclined to keep some data points than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Google Ads', 'BUSINESS', '4.3', '29313', '20M', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'July 30, 2018', '1.12.0', '4.0.3 and up']\n",
      "['Slack', 'BUSINESS', '4.4', '51507', 'Varies with device', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'August 2, 2018', 'Varies with device', 'Varies with device']\n",
      "['Google Ads', 'BUSINESS', '4.3', '29313', '20M', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'July 30, 2018', '1.12.0', '4.0.3 and up']\n",
      "['Slack', 'BUSINESS', '4.4', '51507', 'Varies with device', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'August 2, 2018', 'Varies with device', 'Varies with device']\n",
      "['Slack', 'BUSINESS', '4.4', '51510', 'Varies with device', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'August 2, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Google Ads', 'BUSINESS', '4.3', '29331', '20M', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'July 30, 2018', '1.12.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android_header)\n",
    "print('\\n')\n",
    "\n",
    "for x in Google_data[1:]:\n",
    "    name = x[0]\n",
    "    if name == 'Slack':\n",
    "        print(x)\n",
    "    elif name == 'Google Ads':\n",
    "        print(x)\n",
    "    elif name == 'Instagram':\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the data entries for the same app can differ in the number of reviews (e.g. Instagram, Slack) or can have the same number of reviews (e.g in our previous example for Box and Zenefits)\n",
    "\n",
    "As such, we should aim at maintaining only one data point per app, with the highest number of ratings in case that number differs. That's because the higher the number of reviews, the more reliable the rating and our data will be. \n",
    "\n",
    "The way to do that is to create a dictionary, where each key contains the highest number of reviews for that particular app. And use that dictionary to create a completely new data set that will containg only one data entry per app. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 10840  Google apps in the Google_data dataset, with 1181 duplicate apps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
